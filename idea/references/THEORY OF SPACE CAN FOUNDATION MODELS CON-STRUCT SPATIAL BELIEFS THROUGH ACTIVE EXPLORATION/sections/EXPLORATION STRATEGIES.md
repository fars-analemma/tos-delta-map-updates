EXPLORATION STRATEGIES
To rigorously evaluate spatial cognition, we distinguish between two capabilities: the ability to acquire information (exploration) and the ability to synthesize it (reasoning). We present two evaluation settings: (i) Active Exploration, where the agent must plan actions to reduce uncertainty, and (ii) Passive Comprehension, where the agent reasons over standardized logs generated by scripted proxies. Uncertainty-Driven On-Policy Exploration. We conduct active evaluation to understand agent ability in exploring the environment to gather necessary information in building spatial belief. In this setting, the evaluated agent must plan and execute its own information-gathering policy. At each step, the agent selects an action based on its observation history and current objective, then receives new observations (text or image). Exploration continues until the agent issues an exploration termination or reaches the step budget. Success requires balancing two goals: maximizing coverage of unknown relations while minimizing action cost. This setting directly reveals whether the agent can recognize what it does not yet know and actively reduce uncertainty through exploration. Passive Exploration via Scripted Proxy Agents. Evaluating THEORY OF SPACE requires disentangling two intertwined factors: how well an agent explores, and how well it reasons about the observations gathered. An agent may fail either due to a suboptimal exploration policy (missing key evidence) or a deficiency in integrating observations into a coherent belief. To isolate the latter, we introduce proxy agents as an exploration control. In this setting, evaluated models are fed a fixed stream of observations generated by a proxy agent. By enforcing a standardized exploration path, we eliminate variance caused by exploration failures, allowing for a fair evaluation of core reasoning abilities across different architectures. We design two scripted proxies to provide standardized exploration logs. The SCOUT agent is used for visual environments, who rotates at each location to guarantee all objects are observed. Leveraging visual cues like distance, these compact logs are sufficient for accurate belief construction. The STRATEGIST agent is used for text environments, which follows a belief-driven edge-coverage policy and actively selects viewpoints to maximally reduce ambiguity in coarse symbolic observations. It is implemented with AC-3 constraint propagation to prune inconsistent hypotheses and ensure relations are uniquely determined. Implementation details for both agents appear in Appendix Â¶ A.1.