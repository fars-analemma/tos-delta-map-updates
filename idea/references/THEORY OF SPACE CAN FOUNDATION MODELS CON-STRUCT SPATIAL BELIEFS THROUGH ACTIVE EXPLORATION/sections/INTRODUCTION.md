INTRODUCTION
Spatial embodied intelligence relies on active exploration. Unlike disembodied systems that passively process fixed observations, an embodied agent could take actions to alter its position in the environment as exploration, selectively acquiring observations needed to construct spatial knowledge for various spatial tasks. Cognitive science shows that such active exploration leads to substantially better spatial understanding than passively receiving the same information, even when observations are identical ~\cite{b19,b7}2013). But exploration isn't simply v front-right, mid distance Turn 90; Observe Turn 180; Go to ; Observe front, near front, mid distance Turn 90; Observe Active Exploration Environment Topdown Spatial Belief front-left, mid distance Go to ; Turn 180; Observe vision observation text observation agent action Evaluation (Pairwise): Where is relative to front, mid distance front-left, mid distance Turn 90; Observe front, near Turn 90; Observe Northeast, slightly far Evaluation (Rotation): Object order if rotate clockwise Representation Map each object to 2D coord predicted 2D coord 1 2 3 4 5 ... about collecting more observations. It is about efficiency, acting under uncertainty to target what is unknown or ambiguous in the agent's spatial belief and maximize information gain. We propose THEORY OF SPACE as a framework that explicitly treats exploration as a first-class decision-making problem, decoupled from any single downstream task, focusing on opening the box of the agent's internal spatial belief. Just as Theory of Mind (ToM) measures how agents model the hidden mental states of others, THEORY OF SPACE assesses an agent's ability to model the hidden physical structure of the world. We define THEORY OF SPACE as an embodied agent's ability to actively construct, revise in a dynamic environment, and exploit an internal spatial belief formed through active exploration. Beyond end-task evaluation, THEORY OF SPACE directly probes what the agent knows, what remains uncertain, and how effectively its actions reduce those uncertainties, measured by the number of exploration steps and the uncertainty resolved per action. Figure 1 provides an overview of THEORY OF SPACE's active exploration, belief probing, and end-task evaluation. We apply THEORY OF SPACE to evaluate multimodal language models, which are promising candidates for embodied agents. By integrating vision and language, they support unified perception, reasoning, and action over time, yet existing foundation-model benchmarks offer little insight into these capabilities. Most current benchmarks fall into two categories: passive ~\cite{b50,b41}Yang et al., 2025c;~\cite{b14}Yang et al., 2025a), where the agent is only asked to reason over given observations, and task-driven ~\cite{b17}Shridhar et al., 2020b;~\cite{b28}Yang et al., 2025b), where the agent must achieve a specific goal (e.g., "find the red chair"). In this work, we propose to systematically evaluate the active process of spatial belief construction. Unlike passive benchmarks, our THEORY OF SPACE benchmark requires agents to actively explore via moving, rotating, and observing to build coherent global beliefs. We implement a scalable environment using ThreeDWorld ~\cite{b12} and Objaverse ~\cite{b10}) that provides Text-based and Vision-based worlds to localize perception versus reasoning failures. After active exploration, we evaluate the process along two axes: (i) belief exploitation via spatial downstream tasks that probe route-level and survey-level knowledge ~\cite{b44,b34}; and (ii) exploration efficiency via the number of exploration steps and the accumulated information gain curve over steps, capturing how quickly an agent reduces uncertainty rather than merely increasing coverage. Finally, we design scripted proxy agents that execute strong reference trajectories to disentangle exploration from reasoning. Our evaluation of state-of-the-art foundation models reveals both promising capability in the pure text world and striking limitations in the vision world under THEORY OF SPACE. Active exploration remains a primary bottleneck. Models perform reasonablely well in passive setting, but degrade when they must actively gather information (e.g., GPT-5.2: 57.1 → 46.0; GEMINI-3 PRO: 60.5 → 57.3; Figure . 2). We also find a major efficiency gap: rule-based proxy agents reach target coverage in ∼ 9 steps, whereas foundation models explore redundantly, requiring ≥ 14 steps without improving belief accuracy. Thus, even when models can reason about spatial tasks (as reflected in passive performance), they fail to autonomously structure the information-gathering needed to solve them. Beyond downstream task scores, a core contribution of THEORY OF SPACE is explicit cognitive-map probing, which provides a direct window into the agent's latent spatial belief as it is constructed and revised. Rather than treating the agent as a black box whose internal state is only inferred from final answers, we prompt the model to expose its evolving cognitive map during exploration, enabling measurement of both belief accuracy and belief uncertainty at each step. This probingbased assessment uniquely supports finegrained diagnosis of how models represent space: it reveals that while perception acts as an initial bottleneck, global beliefs also suffer severely from instability, causing knowledge to degrade over time. This allows us to track belief evolution over time, attribute failures to specific representational breakdowns, and evaluate whether an agent truly "knows what is uncertain" rather than merely producing plausible outputs. Finally, to evaluate the mechanics of dynamic spatial updating, we introduce a False Belief paradigm. By altering the environment (relocating or reorienting objects) after the agent's initial exploration, we uncover a phenomenon we term spatial belief inertia: agents (particularly in vision-based settings) struggle to overwrite obsolete spatial priors with new sensory evidence. Despite directly observing the new configuration, models persist in their initial, now incorrect coordinates. This reveals a critical failure in spatial memory revision, where foundational models lack the plasticity to revise their internal cognitive maps in response to physical changes. An important direction for future work is to extend THEORY OF SPACE beyond single-agent settings to multi-agent exploration, where additional challenges arise around coordination and aligning (or sharing) spatial beliefs across agents.

[IMAGE START]Figure 1 : Figure 1: THEORY OF SPACE: active exploration, probed belief, and evaluation. Left: a top-down view of agent trajectory under partial observability in multiple-room scenes. Middle: the agent's action loop of moving, rotating, and observing in text-or vision-based environments, receiving egocentric observations and updating an internal belief. Right: evaluation through exploitation of the belief in spatial tasks and direct probing via probed cognitive maps.[IMAGE END]


Section references:
[b10]: Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli Vanderbilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, Ali Farhadi. A universe of annotated 3d objects. (2022). A universe of annotated 3d objects
[b12]: Chuang Gan, Jeremy Schwartz, Seth Alter, Damian Mrowca, Martin Schrimpf, James Traer, Julian Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano, Kuno Kim, Elias Wang, Michael Lingelbach, Aidan Curtis, Kevin Feigelis, Daniel Bear, Dan Gutfreund, David Cox, Antonio Torralba, James Dicarlo, Joshua Tenenbaum, Josh Mcdermott, L Daniel. Threedworld: A platform for interactive multi-modal physical simulation. (2021). Threedworld: A platform for interactive multi-modal physical simulation
[b14]: Mohsen Gholami, Ahmad Rezaei, Yong Zhou Weimin, Mohammad Zhang. Spatial reasoning with vision-language models in ego-centric multi-view scenes. (2025). Spatial reasoning with vision-language models in ego-centric multi-view scenes
[b17]: Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, Ali Farhadi. Iqa: Visual question answering in interactive environments. (2018). the IEEE conference on computer vision and pattern recognition
[b19]: Richard Held, Alan Hein. Movement-produced stimulation in the development of visually guided behavior. (1963)
[b28]: Manling Li, Shiyu Zhao, Qineng Wang, Kangrui Wang, Yu Zhou, Sanjana Srivastava, Cem Gokmen, Tony Lee, Li Li, Ruohan Zhang, Weiyu Liu, Percy Liang, Li Fei-Fei, Jiayuan Mao, Jiajun Wu. Embodied agent interface: Benchmarking llms for embodied decision making. (2025). Embodied agent interface: Benchmarking llms for embodied decision making
[b34]: R Daniel. A new framework for understanding the acquisition of spatial knowledge in large-scale environments. Spatial and temporal reasoning in geographic information systems. (1998). A new framework for understanding the acquisition of spatial knowledge in large-scale environments. Spatial and temporal reasoning in geographic information systems
[b41]: Zhengxiang Shi, Qiang Zhang, Aldo Lipani. Stepgame: A new benchmark for robust multihop spatial reasoning in texts. (2022). the AAAI conference on artificial intelligence
[b44]: Alan Siegel, Sheldon White. The development of spatial representations of large-scale environments. (1975)
[b50]: Jason Weston, Antoine Bordes, Sumit Chopra, Alexander Rush, Bart Van Merriënboer, Armand Joulin, Tomas Mikolov. Towards ai-complete question answering: A set of prerequisite toy tasks. (2015). Towards ai-complete question answering: A set of prerequisite toy tasks
[b7]: R Elizabeth, William Chrastil. Active and passive contributions to spatial learning. (2012)