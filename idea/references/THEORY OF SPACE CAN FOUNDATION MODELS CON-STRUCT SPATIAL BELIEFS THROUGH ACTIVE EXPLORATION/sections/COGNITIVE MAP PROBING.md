COGNITIVE MAP PROBING
Instead of treating the spatial belief as a black box, we probe the agent's internal state to distinguish verifying known facts from hypothesizing about the unknown. The agent externalizes its belief via a structured JSON containing a Cognitive Map, which records objects currently or previously observed within the field of view. Representation. For consolidated map, the agent presents its belief as a single, allocentric cognitive map serialized in structured JSON. The map maintains (i) a global layout anchored to the agent's initial pose, and (ii) a local snapshot that records only the currently visible objects with the current pose as origin to diagnose immediate perceptual errors. Metrics. We evaluate consolidated map using three complementary metrics. Positional accuracy (pos.acc) is the Euclidean similarity between predicted and true object coordinates: (K/N ) • e -RMSE/L , where RMSE is the root mean squared error between predicted and ground-truth object positions, L is the RMS ℓ 2 -norm of the positions of all objects in the scene, and K/N is the coverage (the ratio of the number of predicted objects K to the number of ground-truth objects N). Directional accuracy (dir.acc) is the accuracy of directional relationship between each pair of objects. Facing accuracy (facing.acc) is the fraction of objects whose predicted facing matches the ground truth. Using global and local belief representations, we compute a set of diagnostic scores at each turn t (all per-turn except Correctness, which is computed only at the final turn after termination). Unless noted, scores are averaged over turns and scenes: • Correctness (final): Measures the accuracy of the agent's terminal global spatial belief. At the last turn, we evaluate the predicted global map and report a composite score given by the (equally weighted) mean of the three metrics defined above, with weights 1/3 each. We compute dir.acc only for correctness, since the global cognitive map prioritizes consistent pairwise spatial relations. • Perception: Measures how accurately the agent interprets newly observed local structure. We compare the predicted local map to the ground-truth local map for the current field of view (FOV), counting only objects that appear in the FOV for the first time. • Self-tracking: Measures how well the model estimates its own pose over time. We infer the agent's pose from the predicted global map and compare it against the ground-truth agent state. • Stability: Measures whether beliefs about previously observed objects remain non-degrading over time. For each previously observed object, at every subsequent turn we check that its predicted state does not worsen; the per-check score is 1 if the prediction is no worse than in the previous turn. 5 indicate a substantial modality gap between vision and text: performance drops markedly in the vision setting across all metrics, not just belief Correctness. Self-tracking does not appear to be a primary bottleneck, models can often maintain an accurate belief about their own pose.

[TABLE START]Table 5 : Spatial Belief Quality via Cognitive Map Probing. We measure final map correctness and turn-level perception, local global consistency, stability, self-tracking, and uncertainty in textvs. vision-worlds. ori. for orientation and pos. for position. Across models, vision lags text on all metrics, with the largest drop on orientation and stability. <table><row><cell/><cell>o r i.</cell><cell>p o s .</cell><cell>o v e r a ll o r i.</cell><cell cols="2">p o s . o r i.</cell><cell>p o s .</cell><cell>o r i.</cell><cell>p o s .</cell><cell>o r i.</cell><cell>p o s .</cell></row><row><cell>Methods</cell><cell cols="4">Correctness (%) Perception (%)</cell><cell cols="2">Local↔ Global (%)</cell><cell cols="2">Stability (%)</cell><cell>Self-tracking (%)</cell><cell>Uncertainty (%)</cell></row><row><cell/><cell/><cell/><cell/><cell cols="3">Vision-based World</cell><cell/><cell/></row><row><cell>GPT-5.2</cell><cell cols="3">20.2 42.0 32.2 33.5</cell><cell cols="6">72.4 57.9 58.7 65.4 56.4 93.3</cell><cell>64.7</cell><cell>53.7</cell></row><row><cell cols="4">GEMINI-3 PRO 32.2 62.5 52.1 43.8</cell><cell cols="6">68.5 52.9 68.3 61.8 62.0 98.8</cell><cell>73.9</cell><cell>70.2</cell></row><row><cell/><cell/><cell/><cell/><cell cols="3">Text-based World</cell><cell/><cell/></row><row><cell>GPT-5.2</cell><cell cols="3">91.0 75.1 80.0 100</cell><cell cols="6">86.8 96.4 86.0 96.7 67.6 98.0</cell><cell>86.7</cell><cell>64.5</cell></row><row><cell cols="4">GEMINI-3 PRO 92.5 75.5 81.4 99.9</cell><cell cols="6">88.2 91.6 84.8 90.8 67.7 99.9</cell><cell>85.2</cell><cell>79.2</cell></row></table>[TABLE END]
